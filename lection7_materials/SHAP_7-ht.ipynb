{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Грузим библиотечки\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# !pip install category_encoders\n",
    "\n",
    "import catboost as ctb\n",
    "import category_encoders as ce\n",
    "\n",
    "# !pip install shap\n",
    "\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и одну функцю оценки модели:\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Обучить и оценить модель.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train, classifier__verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='binary')\n",
    "    rec = recall_score(y_test, y_pred, average='binary')\n",
    "    \n",
    "    return (model, {'f1': [f1], 'roc-auc': [roc], 'precision': [prec], 'recall': [rec]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1: взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть будет этот: https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender  \\\n",
       "0         8949  city_103                   0.920   Male   \n",
       "1        29725   city_40                   0.776   Male   \n",
       "2        11561   city_21                   0.624    NaN   \n",
       "3        33241  city_115                   0.789    NaN   \n",
       "4          666  city_162                   0.767   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level  \\\n",
       "0  Has relevent experience       no_enrollment        Graduate   \n",
       "1   No relevent experience       no_enrollment        Graduate   \n",
       "2   No relevent experience    Full time course        Graduate   \n",
       "3   No relevent experience                 NaN        Graduate   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size    company_type last_new_job  \\\n",
       "0             STEM        >20          NaN             NaN            1   \n",
       "1             STEM         15        50-99         Pvt Ltd           >4   \n",
       "2             STEM          5          NaN             NaN        never   \n",
       "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4             STEM        >20        50-99  Funded Startup            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              36     1.0  \n",
       "1              47     0.0  \n",
       "2              83     0.0  \n",
       "3              52     1.0  \n",
       "4               8     0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"aug_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2: сделать обзорный анализ выбранного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19158, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим общие данные датасета:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             19158 non-null  int64  \n",
      " 1   city                    19158 non-null  object \n",
      " 2   city_development_index  19158 non-null  float64\n",
      " 3   gender                  14650 non-null  object \n",
      " 4   relevent_experience     19158 non-null  object \n",
      " 5   enrolled_university     18772 non-null  object \n",
      " 6   education_level         18698 non-null  object \n",
      " 7   major_discipline        16345 non-null  object \n",
      " 8   experience              19093 non-null  object \n",
      " 9   company_size            13220 non-null  object \n",
      " 10  company_type            13018 non-null  object \n",
      " 11  last_new_job            18735 non-null  object \n",
      " 12  training_hours          19158 non-null  int64  \n",
      " 13  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19158.000000</td>\n",
       "      <td>19158.000000</td>\n",
       "      <td>19158.000000</td>\n",
       "      <td>19158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16875.358179</td>\n",
       "      <td>0.828848</td>\n",
       "      <td>65.366896</td>\n",
       "      <td>0.249348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9616.292592</td>\n",
       "      <td>0.123362</td>\n",
       "      <td>60.058462</td>\n",
       "      <td>0.432647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8554.250000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16982.500000</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25169.750000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33380.000000</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id  city_development_index  training_hours        target\n",
       "count  19158.000000            19158.000000    19158.000000  19158.000000\n",
       "mean   16875.358179                0.828848       65.366896      0.249348\n",
       "std     9616.292592                0.123362       60.058462      0.432647\n",
       "min        1.000000                0.448000        1.000000      0.000000\n",
       "25%     8554.250000                0.740000       23.000000      0.000000\n",
       "50%    16982.500000                0.903000       47.000000      0.000000\n",
       "75%    25169.750000                0.920000       88.000000      0.000000\n",
       "max    33380.000000                0.949000      336.000000      1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем таргет в int, т.к. у нас задача классификации, а не регрессии:\n",
    "\n",
    "df['target'] = df['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14381\n",
       "1     4777\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Что с балансом таргета?\n",
    "\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть небольшой дисбаланс, но всё не так плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кардинальность city: 123\n",
      "Кардинальность gender: 3\n",
      "Кардинальность relevent_experience: 2\n",
      "Кардинальность enrolled_university: 3\n",
      "Кардинальность education_level: 5\n",
      "Кардинальность major_discipline: 6\n",
      "Кардинальность experience: 22\n",
      "Кардинальность company_size: 8\n",
      "Кардинальность company_type: 6\n",
      "Кардинальность last_new_job: 6\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим кардинальность категориальных (object) фичей:\n",
    "\n",
    "for feat in df.select_dtypes('object').columns:\n",
    "    print(f'Кардинальность {feat}: {df[feat].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попробовать сделать one-hot encoding для признаков с кардинальностью < 10.\n",
    "\n",
    "Посмотрим, какие категории есть у признака experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ">20    3286\n",
       "5      1430\n",
       "4      1403\n",
       "3      1354\n",
       "6      1216\n",
       "2      1127\n",
       "7      1028\n",
       "10      985\n",
       "9       980\n",
       "8       802\n",
       "15      686\n",
       "11      664\n",
       "14      586\n",
       "1       549\n",
       "<1      522\n",
       "16      508\n",
       "12      494\n",
       "13      399\n",
       "17      342\n",
       "19      304\n",
       "18      280\n",
       "20      148\n",
       "Name: experience, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['experience'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это просто кол-во лет опыта работы. Можно заменить \">20\" на 21, \"<1\" на 0.\n",
    "\n",
    "Признак city - явно просто города, в которых работают сотрудники. \n",
    "Чтобы закодировать этот признак используем CatBoostEncoder из библиотеки category_encoders.\n",
    "\n",
    "Сделаем кодирование признаков в следующем задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3: сделать feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем числовые и категориальные признаки:\n",
    "\n",
    "num_feats = df.select_dtypes('number').drop(columns='target').columns\n",
    "\n",
    "cat_feats = df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не будем брать ненужный признак enrollee_id, т.к. это просто числовой ID сотрудника:\n",
    "\n",
    "num_feats = num_feats.drop('enrollee_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски с помощью SimpleImputer для всех категориальных признаков (на случай отсутствия будущих данных).\n",
    "\n",
    "Заменяем все пропущенные значения категориальных признаков на самое частое значение (моду), числовых - на медиану."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median'))\n",
    "        ])\n",
    "\n",
    "cat_imputer = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "        ])\n",
    "\n",
    "imputers = ColumnTransformer([\n",
    "    ('num_imputer', num_imputer, num_feats),\n",
    "    ('cat_imputer', cat_imputer, cat_feats),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Числовые признаки берем как они есть:\n",
    "\n",
    "class NumberTaker(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline([\n",
    "    ('nums', NumberTaker())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем категориальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding для всех признаков, кроме experience, city (кардинальность < 10):\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('ohe', OneHotEncoder(drop='first', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформер кодирования признака experience:\n",
    "\n",
    "class ExperienceTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # , y=None\n",
    "        X = X.copy()\n",
    "        X.loc[X[self.column_name] == '<1', self.column_name] = 0\n",
    "        X.loc[X[self.column_name] == '>20', self.column_name] = 21\n",
    "        X = X.astype(int)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_transformer = Pipeline([\n",
    "    ('experience_transform', ExperienceTransformer('experience'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем признак city с помощью CatBoostEncoder:\n",
    "\n",
    "city_transformer = Pipeline([\n",
    "    ('city_transform', ce.cat_boost.CatBoostEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем все трансформации в один пайплайн:\n",
    "\n",
    "transformers = ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, num_feats),\n",
    "    ('cat_transformer', cat_transformer, cat_feats.drop(['experience', 'city'])),\n",
    "    ('experience_transformer', experience_transformer, ['experience']),\n",
    "    ('city_transformer', city_transformer, ['city']),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем вместе заполнение пропусков и трансформации.\n",
    "\n",
    "SimpleImputer возвращает данные в numpy.ndarray, поэтому нужно снова создать датафрейм, чтобы выбирать по столбцам признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyToDataFrame(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_names):\n",
    "        self.column_names = column_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X, columns=self.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('imputers', imputers),\n",
    "    ('numpy_to_df', NumpyToDataFrame(num_feats.tolist() + cat_feats.tolist())),\n",
    "    ('transforms', transformers)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4: обучить любой классификатор (какой вам нравится)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на трейн и тест:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']), df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('classifier', ctb.CatBoostClassifier()), # cat_features=['experience', 'city'])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_metrics = evaluate_model(pipeline,\n",
    "                                      X_train,\n",
    "                                      y_train,\n",
    "                                      X_test,\n",
    "                                      y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>roc-auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386555</td>\n",
       "      <td>0.610236</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.289916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1   roc-auc  precision    recall\n",
       "0  0.386555  0.610236   0.579832  0.289916"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5: разобраться с SHAP и построить важности признаков для:\n",
    "#### - всего тестового набора данных (summary_plot - дать интерпретацию)\n",
    "#### - для топ 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shap не поддерживает sklearn Pipeline, поэтому обработаем данные отдельно, чтобы подать их в SHAP Explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data_imputers = ColumnTransformer([\n",
    "            ('num_imputer', num_imputer, num_feats),\n",
    "            ('cat_imputer', cat_imputer, cat_feats),\n",
    "        ])\n",
    "        self.city_ctb_encoder = ce.cat_boost.CatBoostEncoder(return_df=True)\n",
    "        self.ohe_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Imputers\n",
    "        self.data_imputers.fit(X, y)\n",
    "        # Encode city\n",
    "        self.city_ctb_encoder.fit(X['city'], y)\n",
    "        # One-hot encoder\n",
    "        self.ohe_encoder.fit(X[cat_feats.drop(['experience', 'city'])], X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_trans = X.drop(columns=['enrollee_id'])\n",
    "        # Imputers\n",
    "        X_trans = pd.DataFrame(self.data_imputers.transform(X), columns=num_feats.tolist() + cat_feats.tolist())\n",
    "        # Put numeric columns back to numeric\n",
    "        X_trans[['city_development_index',\n",
    "                 'training_hours']] = X_trans[['city_development_index', 'training_hours']].astype(float)\n",
    "        # Encode experience\n",
    "        X_trans.loc[X_trans['experience'] == '<1', 'experience'] = 0\n",
    "        X_trans.loc[X_trans['experience'] == '>20', 'experience'] = 21\n",
    "        X_trans['experience'] = X_trans['experience'].astype(int)\n",
    "        # Encode city\n",
    "        X_trans['city'] = self.city_ctb_encoder.transform(X_trans['city'])\n",
    "        # One-hot for low-cardinality features\n",
    "        X_trans = pd.get_dummies(X_trans, drop_first=True)\n",
    "\n",
    "#         ohe_feats = cat_feats.drop(['experience', 'city']).tolist()\n",
    "#         X_trans = pd.concat([\n",
    "#             X_trans.drop(columns=ohe_feats),\n",
    "#             pd.DataFrame(self.ohe_encoder.transform(X_trans[ohe_feats])),\n",
    "#         ], axis=1)\n",
    "        \n",
    "        return X_trans\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7f8fcbf65292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshap_data_processor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_data_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-581e4bd10d2d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcity_ctb_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# One-hot encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mohe_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_feats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'experience'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'city'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \"\"\"\n\u001b[0;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[0m\u001b[0;32m     61\u001b[0m                              force_all_finite=needs_validation)\n\u001b[0;32m     62\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "shap_data_processor = DataProcessor().fit(X_train, y_train)\n",
    "X_test_trans = shap_data_processor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-31ada6aea753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_trans' is not defined"
     ]
    }
   ],
   "source": [
    "X_test_trans.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
